Cluster Performance Benchmarking

This directory contains the automated benchmarking suite used to monitor the health and performance of the cluster nodes over time.

üöÄ Quick Start & Environment

Python Environment
To run any of the .py plotting or analysis scripts, you must first activate the specific Conda environment:

conda activate BenchmarkingPythonEnvironment



Automation (Cron)
The daily automation is managed via crontab.

Node: The cron job is configured on chip-login1.

You can SSH to that node to edit the crontab (crontab -e) if schedule changes are needed.

üìÇ File Descriptions

1. Core Automation (Bash)

create_study.bash: The "Setup" script. You run this once (or after clearing old data). It generates the directory structure (e.g., N0065536/) and creates a specific SLURM script for every single node on the cluster. It handles logic for assigning the correct partitions (e.g., placing c18-[43-50] into the test partition).

run_study.bash: The "Daily Driver." This script is run by the Cron job every day. It iterates through the test directories and submits the jobs. Crucially, it checks squeue first; if a specific test job is already pending or running, it skips submitting a duplicate to prevent clogging the queue.

power: The binary executable used for the benchmark test.

2. Analysis & Reporting (Python)

check_cluster_health.py: A text-based reporting tool. It looks at the last 3 weeks of data to establish a baseline, then checks today's results. It prints a report flagging any node that is statistically slower (>2 standard deviations) than its peers.

plot_cluster_heatmap.py: Generates visual heatmaps (Green=Fast, Red=Slow) for each partition group. Saves images to the plots/ folder. Best for seeing specific bad nodes over time.

plot_distribution_check.py: Generates histograms and bell curves. It compares the 3-week baseline distribution against today's data points to see if the cluster is behaving normally or if there are outliers.

plot_partition_comparison.py: Generates box plots to compare the average speed of different partitions (e.g., comparing the 2024 nodes vs. the 2021 nodes).

plot_node_performance.py: A utility to plot the history of a single specific node if you need to investigate one machine in detail.

3. Data & Storage

performance_results.csv: The master database. Every time a benchmark job finishes on a node, it appends a row (Timestamp, Node, Time, Memory) to this file.

performance_results.csv.lock: A temporary lock file used by the system to ensure two nodes don't try to write to the CSV at the exact same millisecond.

cron_log.txt: The output log for the daily automation. Check this if you suspect the daily tests aren't running. It contains the "Success" or "Skip" messages from run_study.bash.

N0065536/: The directory containing the individual job folders and SLURM scripts for the current test size.

plots/: The output folder where all PNG graphs generated by the Python scripts are saved.

üêô Maintenance & GitHub

To back up your results and scripts to GitHub, use standard git commands.

Quick Manual Update:

git add .
git commit -m "Daily benchmark results update"
git push


Pro Tip (One-Liner):
You can add this alias to your ~/.bashrc file to update everything with a single command called gitup:

alias gitup='git add . && git commit -m "Update $(date +%F)" && git push'

